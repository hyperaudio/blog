When we first started working on Hyperaudio back in 2012, at the time [Interactive Transcripts](https://en.wikipedia.org/wiki/Interactive_transcripts) were relatively rare - that's when we started figure out how to represent timed-transcripts in a suitable manner, one that would work for both human and computer. Iâ€™ve been wanting to write this rather nerdy blogpost about that for some time.

In 2012 transcription services were few and far between, but one company that stood out from the crowd was [3Play Media](https://www.3playmedia.com/)- joyfully submitting spoken-word audio to 3Play Media would result in not only the text representation but also structured data in the form of JSON. This JSON contained timings for each word transcribed, it's at that time we started thinking about how to represent and store Interactive Transcripts.




